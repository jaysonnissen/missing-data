---
title: "Missing Data Anslysis"
author: "Jayson Nissen"
date: "1/3/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)

library(msm)
library(dplyr)
library(ggplot2)
library(cowplot)
library(hmi)
library(mice)
library(mitools)
library(reshape2)
library(knitr)

library(viridis)

get_density <- function(x, y, n = 100) {
  dens <- MASS::kde2d(x = x, y = y, n = n)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}

library(foreach)

```
#Thoughts
Analyses we whould run. We should run the MI without the grade data in it. This will be informative for our analysis of the LASSO data.

I also realized that I could set the seed for each loop using a function of G,R,P, iteration, and grade, which are all of trhe variables.

# Purpose

This file generates data sets based on the performance and grade models described in the Grades and Test Statistics pdf. Missing values are insterted into the generated data sets based on the participation rates from the Lonestar study. Missing values are then imputed for each simulated class using the MICE package. Missing data is only insterted for the posttest scores. This is approximately true for data collected in class with paper and pencil tests as the participation rates on the pretests tend to be very high. And, it makes the code and analysis easier to write and run.

We calculate summary statistics (Mean, N, and SD) for each class for the pretest and posttest. For the complete dataset, we used all available data. For the missing dataset, we used complete case analysis to calculated these summary statistics. For the multiply imputed datasets we calculated these summary statistics using each of the ten imputed datasets and then averaged them. This means that the SE of the mean cannot be directly calculated from the SD because it does not account for the between imputation variance. It doesn't take overly long to run the analysis so if we want to focus on SE in the future we can retool the whole program for that specifically. The summary statistics for the imputed data sets only include the posttest. No data was missing for the pretest, so the complete pretest summary statistics are the same as the imputed pretest

#Data Generation

##Models for generating data and simulation parameters

This chunk of code, builds the models that are used in generating the data.
Parameters that define grade distributions, coures types, and participation rates were identified in an exploratory analysis of prior data and hard coded into data frames here. 
JN: Robin, These are much nicer and neater than the way that I was getting at this. Thanks!

```{r}
dists <- data.frame(grade = c(4,3,2,1,0),
                    ave = c(0.15,0.25,0.32,0.08,0.17),
                    high = c(0.25,0.31,0.26,0.06,0.09),
                    low = c(0.05,0.15,0.35,0.08,0.36))

dists <- arrange(dists, grade)

eq_course <- data.frame(Course = c(1,2,3,4),
                        int_pre = c(25,25,25,25),
                        slope_pre = c(2,2,2,2),
                        int_post = c(25,43,58,43),
                        slope_post = c(6,6,6,10))

part_rat <- data.frame(grade = c(0,1,2,3,4),
                       zero = c(0.01,0.02,0.05,0.13,0.30),
                       one = c(0.02,0.05,0.18,0.45,0.75),
                       two = c(0.04,0.17,0.49,0.82,0.96),
                       three = c(0.10,0.41,0.81,0.96,0.99),
                       four = c(0.24,0.71,0.95,0.99,1.00))

```
## User defined functions

Function to calculate sd. 

```{r}
sd_eq<-function(x){
  if (x <1 ) print("x should be in percent and range from 0 to 100")
  if (x < 0) stop("'x' must be >= 1")
  if (x > 100) stop("'x' must be <= 100")
  -33.2*(x/100)^2+14.6*(x/100)+16.6}
```
## Code for generating data 

This section of the code defines the variables for the course size and the number of courses. 

The analysis creates a question for MICE when R=0 and G=4 because the total participation rate is less than 10%. So I can run the whole thing with R>0 and then come back and run it again with R=0 and combine the two data sets.

G this is the grade distribution to use it varies from 2 to 4 with 2=ave, 3=high, 4=low
R participation rate it varies from 0 to 4 with zero being the lowest participation rates
P This is the courses performance from the generator seed from 1:4


This section of the code defines the variables for the course size and the number of courses. The GRP variables are useful for generating one set of data but will be integrated into for loops (or the like)
```{r, eval=FALSE, include=FALSE}
C <- 1000 # this is the total class size
K <- 100 #Number of courses
G <- 2 #this is the grade distribution to use it varies from 2 to 4 with 2=ave, 3=high, 4=low
R <- 1 #participation rate it varies from 0 to 4 with zero being the lowest participation rates
P <- 2 #This is the courses performance from the generator seed from 1:4
```

This section builds a data frame that can be filled. It only builds the dataset for one course grade.

The analysis creates a question for MICE when R=0 and G=4 because the total participation rate is less than 10%. So I can run the whole thing with R>0 and then come back and run it again with R=0 and combine the two data sets.
```{r}
#Makes a data frame to fill in the subsequent steps. This data frame is deleted. <- then why create it?? <- I didn't know another way to do it.
#grade is stored in the dists[grade,% of that grade]
#makes dataframe for summary statistics
vars <- c("P", "G", "R", "iteration", 
          paste("full_pre", c("mean", "sd", "n"), sep="_"), 
          paste("full_post", c("mean", "sd", "n"), sep="_"), 
          paste("miss_pre", c("mean", "sd", "n"), sep="_"), 
          paste("miss_post", c("mean", "sd", "n"), sep="_"), 
          "muim_post_mean", "muim_post_sd")

all_df <- data.frame(matrix(NA, nrow=1, ncol=length(vars)))
names(all_df) <- vars

#makes dataframe for all of the data
vars <- c("pre", "post", "grade","P","G","R","iteration","post_miss","intercept", "id",  paste("post_miss", 1:10, sep = "."))
all_data <- data.matrix(matrix(NA, nrow=1, ncol=length(vars)))
colnames(all_data) <- vars

rm(vars)
```

Simulate average pre and post scores for $K$ classes of $C$ students each, using simulationparameters earlier defined. 

```{r}
sim.class <- function(C=1000, G=2, P=1, R=1, grade.lvl=1, k=1){
  set.seed(10000*G+1000*P+100*R+10*k+grade.lvl)
  A_n    <-round(C*dists[grade.lvl,G],0) #Number of students with that grade 
  A_mean <- eq_course[P,2]+dists[grade.lvl,1]*eq_course[P,3] #Mean pretest grade
  A_sd   <- sd_eq(A_mean) #Pretest SD
  B_mean <- eq_course[P,4]+dists[grade.lvl,1]*eq_course[P,5] #Posttest mean
  B_sd   <- sd_eq(B_mean)  #posttest SD
  
  class <- data.frame(pre=rtnorm(A_n,A_mean,A_sd,0,100), 
                      post = rtnorm(A_n,B_mean,B_sd,0,100), 
                      grade = grade.lvl-1, P = P, G=G, R=R)
  class$post_miss<-class$post
  class$post_miss[1:round((1-part_rat[grade.lvl,R+2])*length(class$post_miss),digits = 0)] <-NA
                     
  return(class)
}
```

```{r}
sim.set <- function(k=1){
for(G in 2:4){
for(P in 1:4){
for(R in 0:4){
    full <- foreach(j=1:5,.combine=rbind)%dopar%{sim.class(grade.lvl=j, k = k,G=G,R=R,P=P)}

#This section calculates the MI data set
set.seed(10000*G+1000*P+100*R+10*k)
mi.out <-mice(full[c(7,1,3)],m=10)
complete_imp <- complete(mi.out, "broad")
full<- cbind(full,complete_imp[c(1,4,7,10,13,16,19,22,25,28)])


#Calculates the summary statistics for this class
sum_df_miss <- full %>% filter (!is.na(post_miss)) %>% 
                        summarise(miss_pre_mean=mean(pre), 
                                  miss_pre_sd=sd(pre),
                                  miss_pre_n=length(pre),
                                  miss_post_mean=mean(post), 
                                  miss_post_sd=sd(post),
                                  miss_post_n=length(post))

sum_df_full <- full %>% summarise(full_pre_mean=mean(pre), 
                                  full_pre_sd=sd(pre),
                                  full_pre_n=length(pre),
                                  full_post_mean=mean(post), 
                                  full_post_sd=sd(post),
                                  full_post_n=length(post))

df <- data.frame(P=P,
                 G=G,
                 R=R,
                 iteration=k,
                 muim_post_mean = mean(colMeans(full[c(8:17)])),
                 muim_post_sd = mean(apply(full[c(8:17)],2,sd)))
df<- bind_cols(df,sum_df_full,sum_df_miss)

#Adds the rows to the new data frame.
all_df <- bind_rows(all_df,df) 
}}}
return(all_df)}
```


```{r, eval=FALSE, include=FALSE}
start_time <- Sys.time()
other <- foreach(k=1:20,.combine=rbind)%dopar%{sim.set(k = k)}
end_time <- Sys.time()
end_time-start_time
```

```{r, eval=FALSE, include=FALSE}
save(other, file = )
```


\newpage
# Data Analysis

This chunk of code uploads the dataset for analysis (not shown in pdf).
```{r, eval=FALSE, include=FALSE}
load("data_set_1_15_18")
all_df <- other
all_df <- all_df[complete.cases(all_df),]
rm(other)
```

##Figure of the relationship between participation rate and difference in raw gain

To analyze all of the data at the same time, I needed to normalize the data so that it would be on the same scale. I chose to normalize the data in term of the absolute gain in the complete data set. I used the absolute gain because it is the numerator in common effect sizes such as Hake's Normalized Gain and Cohen's d.
$$\Delta = Mean_{Post}-Mean_{Pre}$$
$$(\Delta_{Missing}-\Delta_{Complete})/\Delta_{Complete}$$ 

This normalization risks exagerating the impact of missing data because courses with very small $\Delta$ can easily have changes in their $\Delta$ of more than 100%. To avoid this exageration I will further dig into the data and break it down into smaller chunks where I won't need to normalize the data and will be able to just look at the posttest means.

This figure illustrates that using complete case analysis to address missing data tends to exagerate the size of the gains in courses. The more data that is missing the larger the exageration. This is due to the relationship between participation and performance that we identified in existing data and integrated into the models that were used in the data. The fit line for complete case analysis ranges from approximately 40% at the lowest participation rates (6-10%) to around 10% at the highest participation rates of around 90%.
In contrast the fit line for the multiple imputation data overlaps 0% for all participation rates.
For both CC and MI the lower the participation rates the larger the variation in the estimated value from the actual value.  
```{r,echo=FALSE}
temp <- all_df
temp$participation <- 100*temp$miss_post_n/temp$full_post_n
temp$miss_gain_dif_perc <- 100*(temp$miss_post_mean-temp$miss_pre_mean)/(temp$full_post_mean-temp$full_pre_mean)-100
temp$muim_gain_dif_perc <- 100*(temp$muim_post_mean-temp$full_pre_mean)/(temp$full_post_mean-temp$full_pre_mean)-100
for_plot<- temp[c(1,19,20,21)]
for_plot<- for_plot[for_plot$P!=4,]
for_plot <-melt(for_plot, id=c("P","participation"))
ggplot(for_plot, aes(x=participation,y=value,color=variable)) + geom_point()+
  geom_hline(aes(yintercept=0))+ geom_smooth(method="lm", se=TRUE)+
  labs(x="Participation Rate(%)", y="Difference in Raw Gain (%)") + 
  scale_color_discrete(name="Method", breaks=c("miss_gain_dif_perc","muim_gain_dif_perc"), 
                       labels=c("Complete Case","Imputed"))+ 
  theme(legend.position = c(.8,.8))
```
### Linear Models

```{r,echo=FALSE}
linregcc <- lm(value~participation,data=for_plot[for_plot$variable=="miss_gain_dif_perc",])
summary(linregcc)
linregmi <- lm(value~participation,data=for_plot[for_plot$variable=="muim_gain_dif_perc",])
summary(linregmi)
```
These models indicate that the linear fit line for the imputed data is not different than zero and that the linear fit line for the CC data is a reasonable fit with an intercept of 40% a slope of -0.37% and explains 15% of the variance in the data.

```{r,echo=FALSE}
G_names <- c(`2` ="Average",`3`="High",`4`="Low")
P_names <- c(`1`="Low",`2`="Medium",`3`="High",`4`="Alt")

for_plot<- temp[c(1:3,19,20,21)]
for_plot <-melt(for_plot, id=c("P","G","R","participation"))
ggplot(for_plot, aes(x=participation,y=value,color=variable)) + geom_point()+
  geom_hline(aes(yintercept=0))+ geom_smooth()+labs(x="Participation Rate(%)", y="Difference in Raw Gain (%)") + 
  scale_color_discrete(name="Method", breaks=c("miss_gain_dif_perc","muim_gain_dif_perc"), labels=c("Complete Case","Imputed"))+ theme(legend.position = "bottom")+ facet_grid(P~G, labeller = labeller(P = as_labeller(P_names), G = as_labeller(G_names)))
```
## Breaking down scatterplot by Grade Distribution and Performance

This scatterplot illustrates that the largest differences in the normalized data is for the low performance group. To get a better sense of these values I need to break down these by the performance variables. 

```{r,echo=FALSE}
for_plot<- temp[c(1:3,19,20,21)]
for_plot<-for_plot[for_plot$P!=1,]
for_plot <-melt(for_plot, id=c("P","G","R","participation"))
ggplot(for_plot, aes(x=participation,y=value,color=variable)) + geom_point()+
  geom_hline(aes(yintercept=0))+ geom_smooth()+labs(x="Participation Rate(%)", y="Difference in Raw Gain (%)") + 
  scale_color_discrete(name="Method", breaks=c("miss_gain_dif_perc","muim_gain_dif_perc"), labels=c("Complete Case","Imputed"))+ theme(legend.position = "bottom")+ facet_grid(P~G, labeller = labeller(P = as_labeller(P_names), G = as_labeller(G_names)))
```

This is interesting. It shows that increasing the relationship between grade and score (slope in Alt) makes the impact of missing data larger. I think that this is something that we should further investigate. The Alt and Medium have the same intercept but different slopes: 6 for medium and 10 for alt.

###Table of posttest scores
This table shows the posttest scores for the complete data for the courses by grade distribution (Average, High, Low) and Performance (Low, Medium, High)

```{r}
for_plot <- all_df %>% group_by(P,G) %>% summarise(mean_full=mean(full_post_mean))

thing <-dcast(for_plot, P~G, value.var = 'mean_full')                                                    
thing$P <-c("Low","Medium","High","Alt")
colnames(thing)<-c("Performance","Average","High","Low")
kable(thing, digits=1)
                               
```
###Table of Gains
This table shows the shift in the complete dataset from pretest to posttest. This is useful information for interpreting the size of the difference in the 
```{r}
for_plot <- all_df %>% group_by(P,G) %>%summarise(gain=mean(full_post_mean)-mean(full_pre_mean))

thing <-dcast(for_plot, P~G, value.var = 'gain')                                                    
thing$P <-c("Low","Medium","High","Alt")
colnames(thing)<-c("Performance","Average","High","Low")
kable(thing, digits=1)
                               
```


```{r}
for_plot <- all_df %>% group_by(P,G,R) %>%summarise(Missing=mean(miss_post_mean)-mean(full_post_mean),
                                                    Imputed=mean(muim_post_mean)-mean(full_post_mean))

for_plot <- melt(for_plot, id=c("P","G","R"))
ggplot(for_plot, aes(x=variable,y=value,fill=factor(R))) + 
  geom_bar(stat = "identity", position="dodge") +theme(legend.position = "bottom")+
  labs(fill='Participation',title="Difference Between Posttest Scores", x="Difference Between Complete and Labelled Dataset",y="Difference in Posttest Scores")+
  facet_grid(P~G, labeller = labeller(P = as_labeller(P_names), G = as_labeller(G_names)))
                                  
```



```{r}
for_plot <- all_df %>% group_by(P,G,R) %>%
  summarise(Missing=mean(miss_post_mean)-mean(miss_pre_mean)-(mean(full_post_mean)-mean(full_pre_mean)),
            Imputed=mean(muim_post_mean)-mean(full_pre_mean)-(mean(full_post_mean)-mean(full_pre_mean)))

for_plot <- melt(for_plot, id=c("P","G","R"))
ggplot(for_plot, aes(x=variable,y=value,fill=factor(R))) + 
  geom_bar(stat = "identity", position="dodge") +theme(legend.position = "bottom")+
  labs(fill='Participation',title="Difference Between Absolute Gains", x="Difference Between Complete and Labelled Dataset",y="Difference in Absolute Gains (%)")+
  facet_grid(P~G, labeller = labeller(P = as_labeller(P_names), G = as_labeller(G_names)))
                                  
```

This set of figures



```{r,echo=FALSE}
for_plot<- temp[c(1:3,8,14,17)]
for_plot<- for_plot[for_plot$P!=4,]
for_plot$density <- get_density(for_plot$full_post_mean,for_plot$miss_post_mean)
ggplot(for_plot, aes(x=full_post_mean,y=miss_post_mean)) + geom_point(color="red", alpha=0.2) + geom_abline(intercept=0,slope=1)+ labs(x="Actual Posttest", y="Calculated Posttest") 
#+ facet_wrap(~G, labeller = labeller( G = as_labeller(G_names)))
```

```{r,echo=FALSE}
for_plot<- temp[c(1:3,8,14,17)]
for_plot<- for_plot[for_plot$P!=4,]
for_plot$density <- get_density(for_plot$full_post_mean,for_plot$muim_post_mean)
ggplot(for_plot, aes(x=full_post_mean,y=muim_post_mean)) + geom_point(color='green', alpha=0.2) + geom_abline(intercept=0,slope=1)+ labs(x="Actual Posttest", y="Calculated Posttest") 
#+ facet_wrap(~G, labeller = labeller( G = as_labeller(G_names)))
```


This code makes a barplot of all of the results. I don't think that it will be useful in the long run. The boxplot is much neater and cleaner and provides the same information



I think what I need is a code chunk that reduces all of the iterations down to one with error bars for the standard deviation and exclude the P=4


```{r,echo=FALSE}
thing <- temp[c(1:5,8,11,14,17)]
thing<-thing[thing$P!=4,]
thing_post<- thing %>% group_by(P,G,R) %>% 
  summarise(full_mean=mean(full_post_mean),full_sd=sd(full_post_mean),
            miss_mean=mean(miss_post_mean),miss_sd=sd(miss_post_mean),
            muim_mean=mean(muim_post_mean),muim_sd=sd(muim_post_mean))
mean_post <- melt(thing_post, id=c("P","G","R","full_mean","full_sd","miss_sd","muim_sd"))
mean_post$variable<-substr(mean_post$variable,1,4)
colnames(mean_post)[9]<-"mean"
mean_post<-mean_post[-c(6,7)]
mean_sd<- melt(thing_post, id=c("P","G","R","full_mean","full_sd","miss_mean","muim_mean"))
mean_sd$variable<-substr(mean_sd$variable,1,4)
colnames(mean_sd)[9]<-"sd"
mean_sd<- mean_sd[-c(6,7)]
thing2 <- left_join(mean_post,mean_sd, by = c("P", "G", "R", "full_mean", "full_sd", "variable"))
ggplot(thing2, aes(x=full_mean, y=mean, color=variable, alpha=0.2)) + geom_point() +geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.1)+
  geom_abline(intercept=0,slope=1)+
  labs(x="Actual Posttest", y="Missing Posttest") + lims(x=c(30,80),y=c(30,80))

AAA<-ggplot(thing2[thing2$P==1,], aes(x=full_mean, y=mean, color=factor(R), shape=variable, alpha=0.2)) + geom_point(size=4) +geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.1)+
  geom_abline(intercept=0,slope=1)+ labs(x="Actual Posttest", y="Missing Posttest") +
  theme(plot.margin = unit(c(6,0,6,0), "pt"), legend.position="bottom")

BBB<-ggplot(thing2[thing2$P==2,], aes(x=full_mean, y=mean, color=factor(R), shape=variable, alpha=0.2)) + geom_point(size=4) +geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.1)+
  geom_abline(intercept=0,slope=1)+
  labs(x="Actual Posttest", y="") +
  theme(plot.margin = unit(c(6,0,6,0), "pt"),legend.position = "bottom")

CCC<-ggplot(thing2[thing2$P==3,], aes(x=full_mean, y=mean, color=factor(R), shape=variable, alpha=0.2)) + geom_point(size=4) +geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.1)+
  geom_abline(intercept=0,slope=1)+
  labs(x="Actual Posttest", y="") +
  theme(plot.margin = unit(c(6,0,6,0), "pt"),legend.position = "bottom")
sim_plots <- plot_grid(AAA+theme(legend.position = "none"),
                       BBB+theme(legend.position = "none"),
                       CCC+theme(legend.position = "none"),
                       align = 'vh',
                       labels=c("A","B","C"),
                       hjust=-1,
                       nrow=1)
legend <- get_legend(AAA)
plot_grid(sim_plots,legend, ncol=1, rel_heights = c(1,.2))

```

### Scatterplot overlaying our simulated data and actual data.

```{r}
#summary statistics for simulated data
for_plot <- all_df[all_df$P!=4,] %>% group_by(P,G) %>%summarise(pre=mean(full_pre_mean), post=mean(full_post_mean))

#Data from the literature and from LASSO for FCI and FMCE scores in intro physics courses. I cleaned up some of the courses with small Ns. I'm not sure that this is the best way to deal with generating these figures because it will be a pain to update.
test_data <- data.frame(
pre_score= c(29.124030, 36.877497, 41.070776, 41.749879, 43.325543, 36.969200, 37.690919, 23.138178, 30.512600, 22.567452, 
              31.566716, 34.761905, 55.314846, 29.930795, 24.504936, 36.904114, 31.353064, 29.248729, 23.880309, 37.971014,
              49.075414, 32.739327, 23.901480, 29.772365, 34.421285, 29.176879, 35.337348, 34.130245,  
              32.222222, 32.777778, 44.626005, 41.661636, 35.852498, 31.022252, 40.184057, 45.271081, 50.825866, 26.529950,
              34.690106, 44.678795, 36.041667, 37.380952, 37.643208, 51.634665, 45.030114, 57.750812, 51.980888, 31.137358,
              40.138195, 34.943715, 28.486673, 34.324469, 44.988432, 44.903660, 38.025836, 37.762412, 25.573306,
              30.153913, 29.230769, 25.517007, 44.927536, 27.031625, 41.326343, 52.407774, 25.362083, 30.598964, 44.976520,
              25.945376, 24.243432, 31.437841, 47.772601, 49.719407, 38.298860, 38.885059, 44.834293, 34.050400, 45.066032,
              30.718826, 43.172490, 48.887511, 47.018401, 36.444988, 30.843887, 25.824843, 34.068115, 37.213510, 34.033918,
              24.458738, 31.702783, 56.207625, 43.411992, 28.039345, 40.403902, 24.680787, 41.815797, 43.243243,
              55.991135, 39.138565, 40.975391, 24.081238, 36.615293, 25.195969, 27.382054, 29.918572, 45.768654, 25.158730,
              24.005569, 25.691057, 27.418984, 29.866798, 24.758345, 24.225106, 43.000000, 31.304348, 34.643272, 51.363636,
              35.238095, 31.304348, 44.833333, 38.471410, 30.289855, 25.533333, 44.833333, 39.362581, 34.800000, 41.498450,
              32.218845, 27.749616, 20.657621, 35.733334, 26.504431, 41.000000, 27.000000, 27.000000, 32.000000,
              24.000000, 27.000000, 35.000000, 18.000000, 28.000000, 28.000000, 30.000000, 42.000000, 33.000000, 32.000000,
              36.000000, 36.000000, 51.000000, 33.000000, 44.000000, 44.000000, 33.000000, 30.000000, 33.000000, 30.000000,
              45.000000, 50.000000, 46.000000, 48.000000, 35.000000, 43.000000, 37.000000, 52.000000, 52.000000, 48.000000,
              36.000000, 34.000000, 44.000000, 59.000000, 46.000000, 55.000000, 70.000000, 71.000000, 70.000000, 71.000000,
              67.000000, 44.000000, 37.000000, 40.000000, 42.000000, 32.000000, 42.000000, 47.000000, 45.000000, 39.000000,
              31.000000, 48.000000, 48.000000, 44.000000, 43.000000, 44.000000, 40.000000, 38.000000, 33.100000, 31.500000,
              69.010000, 71.000000, 70.000000, 70.000000, 67.000000, 67.000000, 67.000000, 50.000000, 66.521000, 47.000000,
              36.581395, 31.720930, 38.000000, 48.000000, 55.000000, 45.000000, 51.000000, 58.000000, 47.000000, 63.300000,
              65.000000, 34.200000, 64.400000, 59.100000, 76.400000, 49.950000, 52.130000, 51.760000, 51.390000, 46.390000,
              45.830000, 47.270000, 42.030000, 52.160000, 48.120000, 49.820000, 49.580000, 52.810000, 40.360000, 46.390000,
              40.740000, 48.020000, 50.190000, 53.490000, 53.360000, 49.430000, 51.480000, 25.810000, 54.120000, 45.010000,
              45.570000, 45.350000, 44.830000, 29.960000, 28.600000, 68.590044, 67.192308, 49.636058, 57.804902, 30.521908,
              29.609909, 27.000000, 23.000000, 28.550000),
post_score= c(43.31552, 46.64263, 72.53631, 75.08334, 74.52569, 66.47561, 63.19250, 32.42285, 43.98018, 22.34786, 37.72561, 45.19875,
              72.58984, 48.85807, 52.45081, 71.41694, 46.59563, 55.31865, 65.83247, 66.90014, 73.73459, 47.49310, 39.33223, 46.78938,
              54.22951, 44.35977, 63.98074, 45.24950, 49.58846, 54.84466, 55.93396, 62.34495, 38.04027, 37.72488,
              47.86692, 62.72844, 60.60795, 33.24649, 49.95600, 64.77393, 63.24959, 56.33760, 73.74312, 82.62410, 62.65921, 83.99530,
              79.68417, 47.64740, 52.58461, 51.84748, 51.42924, 56.85185, 53.33398, 68.61005, 69.93627, 59.19548, 40.75610,
              38.31452, 39.23204, 35.24486, 55.09138, 32.13716, 56.75632, 61.17944, 36.51112, 50.28306, 60.28869, 43.48310, 48.47028,
              60.20994, 61.28456, 67.47206, 63.13039, 74.36519, 57.04742, 60.00819, 67.76547, 65.72729, 67.97396, 65.06781, 69.87096,
              51.64615, 58.58823, 32.75786, 59.82145, 50.69089, 51.15098, 24.81377, 56.97962, 72.22290, 51.39471, 37.53933, 62.26180,
              46.80160, 57.09865, 53.77233, 67.05121, 56.01765, 60.43371, 35.57545, 49.08921, 43.00112, 38.54019, 45.35783,
              68.67892, 39.47822, 40.94776, 33.73846, 35.07629, 35.44125, 36.00810, 29.34871, 62.23693, 47.83825, 61.60400, 69.28754,
              52.82894, 48.37153, 62.64088, 56.48855, 50.82716, 35.52467, 61.83656, 54.22695, 50.87870, 60.08159, 52.79241, 
              51.91212, 36.67550, 50.70111, 54.30591, 57.00000, 45.00000, 48.00000, 79.00000, 50.00000, 42.00000, 62.00000, 74.00000,
              66.00000, 72.00000, 70.00000, 78.00000, 65.00000, 67.00000, 59.00000, 49.00000, 62.00000, 48.00000, 58.00000, 63.00000,
              70.00000, 73.00000, 72.00000, 62.00000, 71.00000, 82.00000, 69.00000, 76.00000, 62.00000, 77.00000, 53.00000, 64.00000,
              63.00000, 75.00000, 68.00000, 63.00000, 58.00000, 84.00000, 72.00000, 81.00000, 78.00000, 85.00000, 86.00000, 88.00000,
              88.00000, 74.00000, 73.00000, 79.00000, 77.00000, 74.00000, 67.00000, 67.00000, 65.00000, 53.00000, 47.00000, 55.00000,
              70.00000, 54.00000, 58.00000, 58.00000, 54.00000, 51.00000, 47.90000, 61.90000, 78.00000, 85.00000, 86.00000, 88.00000,
              88.00000, 89.00000, 92.00000, 83.00000, 69.00000, 80.00000, 51.37209, 50.06977, 49.50000, 55.00000, 60.00000, 54.00000,
              66.00000, 79.00000, 70.00000, 68.00000, 73.60000, 49.50000, 83.90000, 75.90000, 87.60000, 70.29500, 73.58311, 73.78200,
              75.45900, 68.45620, 70.13000, 64.01000, 61.26000, 73.44000, 73.97000, 75.35000, 72.04000, 77.20000, 67.33000, 69.59000,
              65.22000, 71.82000, 74.05000, 72.10000, 78.52000, 75.79000, 79.92000, 35.71000, 64.68000, 56.49000, 62.27000, 62.70000,
              54.15000, 51.58000, 61.50000, 85.42753, 90.23846, 68.08828, 72.29555, 46.13382, 64.63373, 46.00000, 56.00000, 49.51000))

BBB<-ggplot(test_data, aes(pre_score, post_score, alpha = 0.05)) +
  xlim(0,100) + ylim (0,100)+
  geom_smooth(se=FALSE) +
  geom_point(shape = 16, size = 3, show.legend = TRUE) +
  theme_minimal() +
  labs(x=expression(Prescore), y=expression(Postscore)) 
BBB

BBB+geom_point(data=for_plot, aes(x=pre, y=post,size=5, color=factor(P)))


```

###Barplots of participation by grade distribution and missingness
This code makes a barplot of the overall class participation by participation rate for each of the three grade distributions.
```{r,echo=FALSE}
thing <- unique(temp[c(1:3,19)])
ggplot(thing, aes(x=R, y=participation)) +geom_bar(stat="identity", position="dodge")+ facet_wrap(~G,labeller = labeller(G = as_labeller(G_names)))+labs(x="Participation",y="Total Particiaption (%)")

```




#Notes on The MI and  Traditional courses at FIU
these data all come from the Brewe 2010 article.
152 males passed and 46 males failed. 93 women passed and 40 women failed. This works out to 245 passed and 86 failed. THis is a 26% fail rate that is approximately an average grade distributions since there data includes Ds. THe odds ratio was 7.5 to 1. This works out to be an 88% pass rate. I'm not sure how this aligns with the other statistics I lists. For the lecture course the odds ratio was 1.1 to 1, which is a 52% pass rate. This is actually much worse than the low scores.
The lecture course went from 33 to 48 on the FCI. The MI course went from 32 to 62.
MI is high grade G=3 and this is a bit lower than a 3 performance, which is high
Trad is low grade G=4. It is halfway between a low and medium performance course (1,2)

What were the participation rates in those data?  There are 333 in the grades and 258 in the FCI for the MI course.
There are 758 in the FCI and only  N=2824 in the X2 test which includes the 333 in the MI courses leaving 2491.  
Participation rates:
MI: 77% for a high grade distribution this is a R=3,G=3 
Trad: 30% for a low grade distribution this is a R=2,G=4 (really about 1.5)

```{r}
MI <- temp[temp$R==3&temp$G==3,]
MI <- MI[MI$miss_post_mean>50&MI$miss_post_mean<70,]
mean(MI$miss_post_mean)-mean(MI$full_post_mean)
mean(MI$miss_pre_mean)-mean(MI$full_pre_mean)

trad <- temp[temp$R==2&temp$G==4,]
trad <- trad[trad$miss_post_mean>40&trad$miss_post_mean<60,]
mean(trad$miss_post_mean)-mean(trad$full_post_mean)
mean(trad$miss_pre_mean)-mean(trad$full_pre_mean)


```
Based on these estimates the MI course was 32 to 62 but should have been 32 to 60. So a gain of 30 to 28.
The trad course was 33 to 48 but should have been 31.5 to 42.5. so a gain of 15 to 11.
Maybe a next step would be to translate these changes into effect sizes.




#Figures that I have made but don't think are useful

This code chunk builds a boxplot of the pretest, full posttest, missing posttest, and multiply imputed posttest.

```{r,echo=FALSE}
thing<- all_df[complete.cases(all_df),]
thing <- thing[c(3,4,5,8,14,17)]
thing <- melt(thing, id=c("iteration","R"))
ggplot(thing, aes(x=variable,y=value), fill=factor(iteration)) + 
  geom_boxplot(aes(fill=factor(thing$R))) +theme(legend.position = "bottom")+
  labs(fill='Participation')
```


This chunk makes some summary analyses that can be used to compare across the different iterations. I want to use the absolute gain as the normalization factor because the absolute gain is the numerator in both Cohen's d and Hakes g.

```{r}
temp <- all_df[complete.cases(all_df),]
temp$participation <- temp$miss_post_n/temp$full_post_n
ggplot(temp[temp$iteration==1,], aes(x=R,y=participation, group=iteration)) + 
  geom_bar(stat="identity", aes(group=iteration)) +labs(x="Participation Rate",y="Total Participation")

temp$miss_gain_dif_perc <- 100*(temp$miss_post_mean-temp$miss_pre_mean)/(temp$full_post_mean-temp$full_pre_mean)-100
temp$muim_gain_dif_perc <- 100*(temp$muim_post_mean-temp$full_pre_mean)/(temp$full_post_mean-temp$full_pre_mean)-100

for_plot<- temp[c(3,4,20,21)]
for_plot <- melt(for_plot, id=c("R","iteration"))
ggplot(for_plot, aes(x=variable,y=value), fill=factor(iteration)) + 
  geom_boxplot(aes(fill=factor(R))) +theme(legend.position = "bottom")+
  labs(fill='Participation', x="",y="Difference in Raw Gain (%)")+geom_hline(aes(yintercept=0))
```

```{r, echo=FALSE}
for_plot <- all_df %>% group_by(P,G,R) %>%summarise(pre_f=mean(full_pre_mean),
                                                    pre_mis=mean(miss_pre_mean))

#                                                    post_f=mean(full_post_mean),
#                                                    post_miss=mean(miss_post_mean),
#                                                    post_imp=mean(muim_post_mean))


for_plot <- melt(for_plot, id=c("P","G","R"))
ggplot(for_plot, aes(x=variable,y=value,fill=factor(R))) + 
  geom_bar(stat = "identity", position="dodge") +theme(legend.position = "bottom")+
  labs(fill='Participation')+
  facet_grid(P~G, labeller = labeller(P = as_labeller(P_names), G = as_labeller(G_names)))
                                  

for_plot <- all_df %>% group_by(P,G,R) %>%summarise(post_f=mean(full_post_mean),
                                                    post_miss=mean(miss_post_mean),
                                                    post_imp=mean(muim_post_mean))


for_plot <- melt(for_plot, id=c("P","G","R"))
ggplot(for_plot[for_plot$G==2,], aes(x=variable,y=value,fill=factor(R))) + 
  geom_bar(stat = "identity", position="dodge") +theme(legend.position = "bottom")+
  labs(fill='Participation')+
  facet_wrap(~P, labeller = labeller(P = as_labeller(P_names)))
                                  
```

```{r}
for_plot<- temp[c(1:3,8,14,17)]
for_plot<- for_plot[for_plot$P!=4,]
for_plot <- melt(for_plot, id=c("P","G","R","full_post_mean"))
ggplot(for_plot, aes(x=full_post_mean,y=value,color=variable)) + geom_point(aes(size=.01,stroke=0)) +geom_abline(intercept=0,slope=1)+
  labs(x="Actual Posttest", y="Calculated Posttest") + 
  scale_color_discrete(name="Method", breaks=c("miss_post_mean","muim_post_mean"), labels=c("Complete Case","Imputed"))+ theme(legend.position = "bottom")+ facet_wrap(~G, labeller = labeller( G = as_labeller(G_names)))
```

```{r,echo=FALSE}
thing <- temp[c(1:5,8,11,14,17)]
thing<-thing[thing$P!=4,]
thing_pre<- thing %>% group_by(P,G,R) %>% summarise(full_mean=mean(full_pre_mean),full_sd=sd(full_pre_mean),
          miss_mean=mean(miss_pre_mean),miss_sd=sd(miss_pre_mean))
ggplot(thing_pre, aes(x=full_mean,y=miss_mean, color=factor(R), shape=factor(P))) + geom_point(size=4) +
  geom_abline(intercept=0,slope=1)+ labs(x="Actual Pretest", y="Missing Pretest") + geom_errorbar(aes(ymin=miss_mean-miss_sd, ymax=miss_mean+miss_sd), width=.1) 
```

```{r, echo=FALSE}
for_plot <- all_df %>% group_by(P,G,R) %>%summarise(delta_miss=mean(miss_post_mean)-mean(full_post_mean),
                                                    delta_imp=mean(muim_post_mean)-mean(full_post_mean))


for_plot <- melt(for_plot, id=c("P","G","R"))
ggplot(for_plot[for_plot$G==2,], aes(x=variable,y=value,fill=factor(R))) + 
  geom_bar(stat = "identity", position="dodge") +theme(legend.position = "bottom")+
  labs(fill='Participation')+
  facet_wrap(~P, labeller = labeller(P = as_labeller(P_names)))
                                  
```